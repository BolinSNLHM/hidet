# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer((512, 512), "float32"), B: T.Buffer((512, 512), "float32"), matmul_ansor: T.Buffer((512, 512), "float32")):
        T.func_attr({"from_legacy_te_schedule": T.bool(True), "global_symbol": "main", "tir.noalias": T.bool(True)})
        auto_scheduler_layout_transform = T.allocate([262144], "float32", "global")
        auto_scheduler_layout_transform_1 = T.Buffer((262144,), data=auto_scheduler_layout_transform)
        for ax0_ax1_fused_ax2_fused in T.parallel(32):
            for ax3, ax6 in T.grid(512, 16):
                B_1 = T.Buffer((262144,), data=B.data)
                auto_scheduler_layout_transform_1[ax0_ax1_fused_ax2_fused * 8192 + ax3 * 16 + ax6] = B_1[ax3 * 512 + ax0_ax1_fused_ax2_fused * 16 + ax6]
        for i_outer_j_outer_fused in T.parallel(16):
            matmul_ansor_local = T.allocate([16384], "float32", "local")
            matmul_ansor_local_1 = T.Buffer((16384,), data=matmul_ansor_local, scope="local")
            for i_c_outer_outer_inner, j_c_outer_outer_inner in T.grid(128, 2):
                cse_var_1: T.int32 = i_c_outer_outer_inner * 128 + j_c_outer_outer_inner * 16
                matmul_ansor_local_1[cse_var_1:cse_var_1 + 16] = T.Broadcast(T.float32(0), 16)
                matmul_ansor_local_1[cse_var_1 + 32:cse_var_1 + 32 + 16] = T.Broadcast(T.float32(0), 16)
                matmul_ansor_local_1[cse_var_1 + 64:cse_var_1 + 64 + 16] = T.Broadcast(T.float32(0), 16)
                matmul_ansor_local_1[cse_var_1 + 96:cse_var_1 + 96 + 16] = T.Broadcast(T.float32(0), 16)
                for k_outer in range(512):
                    cse_var_6: T.int32 = cse_var_1 + 96
                    cse_var_5: T.int32 = cse_var_1 + 64
                    cse_var_4: T.int32 = cse_var_1 + 32
                    cse_var_3: T.int32 = i_c_outer_outer_inner * 2048 + k_outer
                    cse_var_2: T.int32 = i_outer_j_outer_fused * 16384 + j_c_outer_outer_inner * 8192 + k_outer * 16
                    A_1 = T.Buffer((262144,), data=A.data)
                    matmul_ansor_local_1[cse_var_1:cse_var_1 + 16] = matmul_ansor_local_1[cse_var_1:cse_var_1 + 16] + T.Broadcast(A_1[cse_var_3], 16) * auto_scheduler_layout_transform_1[cse_var_2:cse_var_2 + 16]
                    matmul_ansor_local_1[cse_var_4:cse_var_4 + 16] = matmul_ansor_local_1[cse_var_4:cse_var_4 + 16] + T.Broadcast(A_1[cse_var_3 + 512], 16) * auto_scheduler_layout_transform_1[cse_var_2:cse_var_2 + 16]
                    matmul_ansor_local_1[cse_var_5:cse_var_5 + 16] = matmul_ansor_local_1[cse_var_5:cse_var_5 + 16] + T.Broadcast(A_1[cse_var_3 + 1024], 16) * auto_scheduler_layout_transform_1[cse_var_2:cse_var_2 + 16]
                    matmul_ansor_local_1[cse_var_6:cse_var_6 + 16] = matmul_ansor_local_1[cse_var_6:cse_var_6 + 16] + T.Broadcast(A_1[cse_var_3 + 1536], 16) * auto_scheduler_layout_transform_1[cse_var_2:cse_var_2 + 16]
            for i_inner in range(512):
                matmul_ansor_1 = T.Buffer((262144,), data=matmul_ansor.data)
                matmul_ansor_1[i_inner * 512 + i_outer_j_outer_fused * 32:i_inner * 512 + i_outer_j_outer_fused * 32 + 32] = matmul_ansor_local_1[i_inner * 32:i_inner * 32 + 32]